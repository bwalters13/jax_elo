{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom EloFunctions\n",
    "\n",
    "This example walks through the creation of a custom Elo algorithm taking into account the different formats used in tennis matches.\n",
    "\n",
    "Tennis matches on the men's professional circuit are broadly played in two formats: best of three sets, and best of five sets. Best of five set matches are longer and have been shown to be less prone to upsets, so the better player is more likely to win than in a best of three set match (see for example [here](https://www.degruyter.com/view/j/jqas.2018.14.issue-1/jqas-2017-0077/jqas-2017-0077.xml) for more details).\n",
    "\n",
    "From a model perspective, rather than using the usual win probability of:\n",
    "\n",
    "$p(win | \\delta) = \\textrm{logit}^{-1}(b \\delta)$\n",
    "\n",
    "where $b = \\log(10) / 400$ to match Elo's win probability, we could instead model it as:\n",
    "\n",
    "$p(win | \\delta) = \\textrm{logit}^{-1}(b * (1 + \\textrm{is_bo5} * \\textrm{bo5_factor}) * \\delta)$\n",
    "\n",
    "where is_bo5 is an indicator of whether it's a best of five match, and bo5_factor is the (most likely positive) addition when it's a best of five match.\n",
    "\n",
    "In the following, we walk through how to specify `EloFunctions` to use with this framework to take this into account. To do this, we're going to build off the \"basic.py\" functions found in `jax_elo/elo_functions/basic.py` to keep things simple, so we won't be including a margin of victory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ingramm/miniconda3/envs/tf/lib/python3.7/site-packages/jax/lib/xla_bridge.py:116: UserWarning: No GPU/TPU found, falling back to CPU.\n",
      "  warnings.warn('No GPU/TPU found, falling back to CPU.')\n"
     ]
    }
   ],
   "source": [
    "# We first import what we'll need:\n",
    "from functools import partial\n",
    "\n",
    "import jax.numpy as jnp\n",
    "from jax import jit, grad, hessian\n",
    "from jax.scipy.special import expit\n",
    "from jax.scipy.stats import multivariate_normal\n",
    "\n",
    "from jax_elo.utils.normals import weighted_sum, logistic_normal_integral_approx\n",
    "from jax_elo.core import EloFunctions, calculate_win_prob\n",
    "from jax_elo.utils.flattening import reconstruct\n",
    "\n",
    "# The pre-factor to switch to the Elo scale, as discussed\n",
    "b = jnp.log(10) / 400.\n",
    "\n",
    "\n",
    "# First, we specify the (log) likelihood.\n",
    "@jit\n",
    "def calculate_likelihood(x, mu, a, theta, y):\n",
    "    \n",
    "    # a @ x will give us the skill difference (see paper for details):\n",
    "    delta = a @ x\n",
    "    \n",
    "    # Now we'll assume that y[0] is the bo5 indicator:\n",
    "    is_bo5 = y[0]\n",
    "    \n",
    "    # Now we write down the log likelihood as discussed\n",
    "    # We'll have to make sure to include the bo5 factor in the dictionary of parameters theta later.\n",
    "    win_prob = jnp.log(\n",
    "        expit(b * (1 + is_bo5 * theta['bo5_factor']) * delta))\n",
    "\n",
    "    return win_prob\n",
    "\n",
    "# Now, we need to modify the (log) marginal likelihood in a similar way.\n",
    "@jit\n",
    "def calculate_marginal_lik(x, mu, a, cov_mat, theta, y):\n",
    "\n",
    "    # This gives the mean and variance of delta:\n",
    "    latent_mean, latent_var = weighted_sum(x, cov_mat, a)\n",
    "        \n",
    "    # Define our new multiplier:\n",
    "    is_bo5 = y[0]\n",
    "    multiplier = b * (1 + is_bo5 * theta['bo5_factor'])\n",
    "    \n",
    "    # Multiplying a normal random variable with mean mu and variance sigma^2\n",
    "    # by a factor c will yield a new normal distribution with mean c * mu and\n",
    "    # variance c^2 sigma^2, so we use that to calculate the integral approximation:\n",
    "    win_prob = jnp.log(logistic_normal_integral_approx(\n",
    "        multiplier * latent_mean, multiplier**2 * latent_var))\n",
    "\n",
    "    return win_prob\n",
    "\n",
    "# The (log) prior here is multivariate normal to account for correlated skills:\n",
    "@jit\n",
    "def calculate_prior(x, mu, cov_mat, theta):\n",
    "\n",
    "    return multivariate_normal.logpdf(x, mu, cov_mat)\n",
    "\n",
    "\n",
    "# The log posterior is the log_prior plus the log_likelihood:\n",
    "@jit\n",
    "def calculate_log_posterior(x, mu, cov_mat, a, theta, y):\n",
    "\n",
    "    return (calculate_likelihood(x, mu, a, theta, y) +\n",
    "            calculate_prior(x, mu, cov_mat, theta))\n",
    "\n",
    "# The parse_theta function has to make the dictionary theta from a flat vector\n",
    "# to use in the optimisation.\n",
    "def parse_theta(flat_theta, summary):\n",
    "    # Either do this manually:\n",
    "    # return {'bo5_factor': flat_theta[0]}\n",
    "    \n",
    "    # Or use the reconstruct utility function:\n",
    "    return reconstruct(flat_theta, summary, jnp.reshape)\n",
    "\n",
    "# Finally, we need to define a new win probability function:\n",
    "def calculate_win_prob_bo5(mu1, mu2, a, y, elo_params):\n",
    "    \n",
    "    is_bo5 = y[0]\n",
    "    pre_factor = b * (1 + is_bo5 * elo_params.theta['bo5_factor'])\n",
    "    \n",
    "    # We can use the usual function since it has a pre_factor argument:\n",
    "    return calculate_win_prob(mu1, mu2, a, y, elo_params, \n",
    "                              pre_factor=pre_factor)\n",
    "\n",
    "# Now we put these together into the Tuple of EloFunctions, using\n",
    "# JAX to compute the Jacobian and Hessian needed for the update:\n",
    "bo5_functions = EloFunctions(\n",
    "    log_post_jac_x=jit(grad(calculate_log_posterior)),\n",
    "    log_post_hess_x=jit(hessian(calculate_log_posterior)),\n",
    "    marginal_lik_fun=calculate_marginal_lik,\n",
    "    parse_theta_fun=parse_theta,\n",
    "    win_prob_fun=jit(calculate_win_prob_bo5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's try it. Get the data:\n",
    "from jax_elo.utils.data import get_data\n",
    "\n",
    "# Point this to where your tennis_atp dataset is\n",
    "df = get_data('/Users/ingramm/Projects/tennis/tennis-data/data/sackmann/tennis_atp/')\n",
    "\n",
    "# Use only some recent years\n",
    "to_use = df[df['tourney_date'].dt.year >= 2016]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's optimise the parameters:\n",
    "# Let's not make it surface specific to start with\n",
    "from jax_elo.core import optimise_elo, EloParams, calculate_ratings_history\n",
    "from jax_elo.utils.encoding import encode_players\n",
    "\n",
    "start_theta = {'bo5_factor': jnp.array(0.)}\n",
    "start_cov_mat = jnp.eye(1) * 100**2\n",
    "\n",
    "start_params = EloParams(theta=start_theta, cov_mat=start_cov_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "winner_ids, loser_ids, unique_players = encode_players(to_use['winner_name'].values, to_use['loser_name'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_matches = len(winner_ids)\n",
    "\n",
    "# We're not using surfaces here, so a is just [1, -1] for each match:\n",
    "a = jnp.stack([jnp.ones(n_matches), -jnp.ones(n_matches)], axis=1)\n",
    "\n",
    "# y is more interesting. We need a best of five indicator.\n",
    "# We'll just use slams here. This isn't quite right: some other tournaments are best of five.\n",
    "# But let's keep it simple here.\n",
    "is_bo5 = to_use['tourney_name'].isin(['Australian Open', 'Roland Garros', 'Wimbledon', 'US Open']).values\n",
    "\n",
    "# We need a 2D array, so reshape:\n",
    "y = is_bo5.reshape(-1, 1).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta: {'bo5_factor': array(0.)}\n",
      "cov_mat: [[10000.000001]]\n",
      "theta: {'bo5_factor': Traced<ShapedArray(float64[])>with<JVPTrace(level=1/1)>\n",
      "  with primal = Traced<ShapedArray(float64[]):JaxprTrace(level=-1/1)>\n",
      "       tangent = Traced<ShapedArray(float64[]):JaxprTrace(level=0/1)>}\n",
      "cov_mat: Traced<ShapedArray(float64[1,1])>with<JVPTrace(level=1/1)>\n",
      "  with primal = Traced<ShapedArray(float64[1,1]):JaxprTrace(level=-1/1)>\n",
      "       tangent = Traced<ShapedArray(float64[1,1]):JaxprTrace(level=0/1)>\n",
      "theta: {'bo5_factor': array(1.00962673)}\n",
      "cov_mat: [[9994.50940957]]\n",
      "theta: {'bo5_factor': array(0.26884322)}\n",
      "cov_mat: [[9998.53782003]]\n",
      "theta: {'bo5_factor': array(0.2627341)}\n",
      "cov_mat: [[9646.86446026]]\n",
      "theta: {'bo5_factor': array(0.23829764)}\n",
      "cov_mat: [[8303.12929485]]\n",
      "theta: {'bo5_factor': array(0.38140337)}\n",
      "cov_mat: [[5295.93839301]]\n",
      "theta: {'bo5_factor': array(0.43328075)}\n",
      "cov_mat: [[5958.91338351]]\n",
      "theta: {'bo5_factor': array(0.49059268)}\n",
      "cov_mat: [[5811.1318405]]\n",
      "theta: {'bo5_factor': array(0.52381784)}\n",
      "cov_mat: [[5708.47930333]]\n",
      "theta: {'bo5_factor': array(0.52651785)}\n",
      "cov_mat: [[5703.95911409]]\n",
      "theta: {'bo5_factor': array(0.5266267)}\n",
      "cov_mat: [[5704.04680952]]\n",
      "theta: {'bo5_factor': array(0.52662679)}\n",
      "cov_mat: [[5704.06147268]]\n"
     ]
    }
   ],
   "source": [
    "# Now we're ready to optimise the parameters:\n",
    "opt_params, opt_results = optimise_elo(start_params, bo5_functions, winner_ids, loser_ids, a, y,\n",
    "                                       len(unique_players), tol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.52662679)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The estimated optimal bo5 factor\n",
    "opt_params.theta['bo5_factor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[5704.06147268]], dtype=float64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The estimated prior covariance matrix\n",
    "# Here we only have one skill, so it's 1x1\n",
    "opt_params.cov_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the final parameters to predict & evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10850 [00:00<?, ?it/s]\n",
      "  0%|          | 0/10850 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 1/10850 [00:00<1:03:10,  2.86it/s]\u001b[A\n",
      "  0%|          | 49/10850 [00:00<44:08,  4.08it/s] \u001b[A\n",
      "  1%|          | 117/10850 [00:00<30:47,  5.81it/s]\u001b[A\n",
      "  2%|▏         | 185/10850 [00:00<21:29,  8.27it/s]\u001b[A\n",
      "  2%|▏         | 269/10850 [00:00<14:59, 11.76it/s]\u001b[A\n",
      "  3%|▎         | 354/10850 [00:00<10:28, 16.71it/s]\u001b[A\n",
      "  4%|▍         | 428/10850 [00:00<07:20, 23.63it/s]\u001b[A\n",
      "  5%|▍         | 508/10850 [00:01<05:10, 33.34it/s]\u001b[A\n",
      "  5%|▌         | 579/10850 [00:01<03:40, 46.61it/s]\u001b[A\n",
      "  6%|▌         | 663/10850 [00:01<02:36, 65.01it/s]\u001b[A\n",
      "  7%|▋         | 745/10850 [00:01<01:52, 89.79it/s]\u001b[A\n",
      "  8%|▊         | 845/10850 [00:01<01:21, 123.47it/s]\u001b[A\n",
      "  9%|▉         | 955/10850 [00:01<00:58, 168.27it/s]\u001b[A\n",
      " 10%|▉         | 1064/10850 [00:01<00:43, 225.37it/s]\u001b[A\n",
      " 11%|█         | 1168/10850 [00:01<00:32, 294.40it/s]\u001b[A\n",
      " 12%|█▏        | 1267/10850 [00:01<00:25, 370.47it/s]\u001b[A\n",
      " 13%|█▎        | 1364/10850 [00:01<00:21, 447.10it/s]\u001b[A\n",
      " 13%|█▎        | 1458/10850 [00:02<00:17, 525.64it/s]\u001b[A\n",
      " 14%|█▍        | 1551/10850 [00:02<00:15, 590.25it/s]\u001b[A\n",
      " 15%|█▌        | 1641/10850 [00:02<00:14, 645.23it/s]\u001b[A\n",
      " 16%|█▌        | 1729/10850 [00:02<00:13, 694.83it/s]\u001b[A\n",
      " 17%|█▋        | 1816/10850 [00:02<00:14, 605.31it/s]\u001b[A\n",
      " 18%|█▊        | 1919/10850 [00:02<00:12, 688.77it/s]\u001b[A\n",
      " 19%|█▊        | 2009/10850 [00:02<00:11, 739.47it/s]\u001b[A\n",
      " 19%|█▉        | 2101/10850 [00:02<00:11, 782.52it/s]\u001b[A\n",
      " 20%|██        | 2188/10850 [00:03<00:11, 753.12it/s]\u001b[A\n",
      " 21%|██        | 2279/10850 [00:03<00:10, 793.27it/s]\u001b[A\n",
      " 22%|██▏       | 2377/10850 [00:03<00:10, 841.00it/s]\u001b[A\n",
      " 23%|██▎       | 2466/10850 [00:03<00:09, 840.06it/s]\u001b[A\n",
      " 24%|██▎       | 2553/10850 [00:03<00:10, 781.87it/s]\u001b[A\n",
      " 24%|██▍       | 2635/10850 [00:03<00:10, 792.44it/s]\u001b[A\n",
      " 25%|██▌       | 2726/10850 [00:03<00:09, 823.74it/s]\u001b[A\n",
      " 26%|██▌       | 2813/10850 [00:03<00:09, 833.94it/s]\u001b[A\n",
      " 27%|██▋       | 2900/10850 [00:03<00:09, 843.80it/s]\u001b[A\n",
      " 28%|██▊       | 2991/10850 [00:03<00:09, 861.52it/s]\u001b[A\n",
      " 29%|██▊       | 3098/10850 [00:04<00:08, 913.63it/s]\u001b[A\n",
      " 29%|██▉       | 3191/10850 [00:04<00:08, 909.92it/s]\u001b[A\n",
      " 30%|███       | 3283/10850 [00:04<00:08, 896.37it/s]\u001b[A\n",
      " 31%|███       | 3374/10850 [00:04<00:08, 889.84it/s]\u001b[A\n",
      " 32%|███▏      | 3464/10850 [00:04<00:08, 891.69it/s]\u001b[A\n",
      " 33%|███▎      | 3572/10850 [00:04<00:07, 938.27it/s]\u001b[A\n",
      " 34%|███▍      | 3692/10850 [00:04<00:07, 1002.89it/s][A\n",
      " 35%|███▌      | 3802/10850 [00:04<00:06, 1030.10it/s]\u001b[A\n",
      " 36%|███▌      | 3915/10850 [00:04<00:06, 1057.53it/s]\u001b[A\n",
      " 37%|███▋      | 4022/10850 [00:05<00:06, 1030.28it/s]\u001b[A\n",
      " 38%|███▊      | 4131/10850 [00:05<00:06, 1044.87it/s]\u001b[A\n",
      " 39%|███▉      | 4237/10850 [00:05<00:06, 1023.06it/s]\u001b[A\n",
      " 40%|████      | 4340/10850 [00:05<00:06, 958.83it/s] \u001b[A\n",
      " 41%|████      | 4438/10850 [00:05<00:07, 872.59it/s]\u001b[A\n",
      " 42%|████▏     | 4528/10850 [00:05<00:07, 875.68it/s]\u001b[A\n",
      " 43%|████▎     | 4622/10850 [00:05<00:06, 891.87it/s]\u001b[A\n",
      " 44%|████▎     | 4736/10850 [00:05<00:06, 954.02it/s]\u001b[A\n",
      " 45%|████▍     | 4848/10850 [00:05<00:06, 997.58it/s]\u001b[A\n",
      " 46%|████▌     | 4950/10850 [00:05<00:05, 996.12it/s]\u001b[A\n",
      " 47%|████▋     | 5074/10850 [00:06<00:05, 1057.92it/s]\u001b[A\n",
      " 48%|████▊     | 5193/10850 [00:06<00:05, 1091.53it/s]\u001b[A\n",
      " 49%|████▉     | 5309/10850 [00:06<00:04, 1109.79it/s]\u001b[A\n",
      " 50%|█████     | 5426/10850 [00:06<00:04, 1125.96it/s]\u001b[A\n",
      " 51%|█████     | 5540/10850 [00:06<00:04, 1097.04it/s]\u001b[A\n",
      " 52%|█████▏    | 5660/10850 [00:06<00:04, 1125.32it/s]\u001b[A\n",
      " 53%|█████▎    | 5781/10850 [00:06<00:04, 1148.18it/s]\u001b[A\n",
      " 54%|█████▍    | 5900/10850 [00:06<00:04, 1159.97it/s]\u001b[A\n",
      " 55%|█████▌    | 6017/10850 [00:06<00:04, 1162.82it/s]\u001b[A\n",
      " 57%|█████▋    | 6134/10850 [00:07<00:04, 1108.28it/s]\u001b[A\n",
      " 58%|█████▊    | 6255/10850 [00:07<00:04, 1135.74it/s]\u001b[A\n",
      " 59%|█████▊    | 6373/10850 [00:07<00:03, 1148.26it/s]\u001b[A\n",
      " 60%|█████▉    | 6489/10850 [00:07<00:03, 1125.28it/s]\u001b[A\n",
      " 61%|██████    | 6607/10850 [00:07<00:03, 1140.00it/s]\u001b[A\n",
      " 62%|██████▏   | 6728/10850 [00:07<00:03, 1157.31it/s]\u001b[A\n",
      " 63%|██████▎   | 6845/10850 [00:07<00:03, 1149.52it/s]\u001b[A\n",
      " 64%|██████▍   | 6961/10850 [00:07<00:03, 1133.07it/s]\u001b[A\n",
      " 65%|██████▌   | 7081/10850 [00:07<00:03, 1150.75it/s]\u001b[A\n",
      " 67%|██████▋   | 7311/10850 [00:08<00:03, 1113.09it/s]\u001b[A\n",
      " 68%|██████▊   | 7430/10850 [00:08<00:03, 1134.53it/s]\u001b[A\n",
      " 70%|██████▉   | 7550/10850 [00:08<00:02, 1151.37it/s]\u001b[A\n",
      " 71%|███████   | 7669/10850 [00:08<00:02, 1161.90it/s]\u001b[A\n",
      " 72%|███████▏  | 7787/10850 [00:08<00:02, 1164.99it/s]\u001b[A\n",
      " 72%|███████▏  | 7788/10850 [00:08<00:02, 1157.14it/s]\u001b[A\n",
      " 74%|███████▍  | 8019/10850 [00:08<00:02, 1091.90it/s]\u001b[A\n",
      " 75%|███████▍  | 8129/10850 [00:08<00:02, 1015.16it/s]\u001b[A\n",
      " 76%|███████▌  | 8232/10850 [00:08<00:02, 970.90it/s] \u001b[A\n",
      " 77%|███████▋  | 8331/10850 [00:09<00:02, 913.06it/s] \u001b[A\n",
      " 77%|███████▋  | 8332/10850 [00:09<00:02, 910.92it/s]\u001b[A\n",
      " 78%|███████▊  | 8425/10850 [00:09<00:02, 898.18it/s]\u001b[A\n",
      " 79%|███████▊  | 8536/10850 [00:09<00:02, 948.14it/s]\u001b[A\n",
      " 80%|███████▉  | 8648/10850 [00:09<00:02, 990.83it/s]]\u001b[A\n",
      " 81%|████████  | 8757/10850 [00:09<00:02, 1011.99it/s]\u001b[A\n",
      " 83%|████████▎ | 8953/10850 [00:09<00:02, 787.42it/s] \u001b[A\n",
      " 83%|████████▎ | 9037/10850 [00:09<00:02, 720.61it/s]\u001b[A\n",
      " 83%|████████▎ | 9038/10850 [00:09<00:02, 711.23it/s]\u001b[A\n",
      " 84%|████████▍ | 9114/10850 [00:10<00:02, 673.08it/s]\u001b[A\n",
      " 85%|████████▍ | 9204/10850 [00:10<00:02, 725.70it/s]\u001b[A\n",
      " 86%|████████▌ | 9297/10850 [00:10<00:02, 767.83it/s]\u001b[A\n",
      " 86%|████████▋ | 9378/10850 [00:10<00:01, 762.44it/s]\u001b[A\n",
      " 87%|████████▋ | 9457/10850 [00:10<00:01, 753.99it/s]\u001b[A\n",
      " 88%|████████▊ | 9535/10850 [00:10<00:01, 741.67it/s]\u001b[A\n",
      " 89%|████████▊ | 9611/10850 [00:10<00:01, 746.01it/s]\u001b[A\n",
      " 90%|████████▉ | 9720/10850 [00:10<00:01, 820.62it/s]\u001b[A\n",
      " 91%|█████████ | 9831/10850 [00:10<00:01, 887.87it/s]\u001b[A\n",
      " 91%|█████████▏| 9924/10850 [00:10<00:01, 863.45it/s]\u001b[A\n",
      " 92%|█████████▏| 10015/10850 [00:11<00:00, 874.40it/s]\u001b[A\n",
      " 93%|█████████▎| 10105/10850 [00:11<00:00, 878.82it/s]\u001b[A\n",
      " 94%|█████████▍| 10195/10850 [00:11<00:00, 866.17it/s]\u001b[A\n",
      " 95%|█████████▍| 10283/10850 [00:11<00:00, 849.34it/s]\u001b[A\n",
      " 96%|█████████▌| 10370/10850 [00:11<00:00, 851.81it/s]\u001b[A\n",
      " 96%|█████████▋| 10457/10850 [00:11<00:00, 855.79it/s]\u001b[A\n",
      " 97%|█████████▋| 10543/10850 [00:11<00:00, 836.58it/s]\u001b[A\n",
      " 98%|█████████▊| 10628/10850 [00:11<00:00, 783.73it/s]\u001b[A\n",
      " 99%|█████████▊| 10712/10850 [00:11<00:00, 798.44it/s]\u001b[A\n",
      "100%|██████████| 10850/10850 [00:12<00:00, 896.78it/s]\u001b[A\n",
      "100%|██████████| 10850/10850 [00:12<00:00, 897.43it/s]\n"
     ]
    }
   ],
   "source": [
    "history, final_ratings = calculate_ratings_history(to_use['winner_name'], to_use['loser_name'], a, y, \n",
    "                                                   bo5_functions, opt_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best of five:  0.63\n",
      "Best of three:  0.593\n"
     ]
    }
   ],
   "source": [
    "# As expected, the optimal factor is greater than zero.\n",
    "# We can compare the win probability at a slam / not a slam:\n",
    "p1 = 'Novak Djokovic'\n",
    "p2 = 'Rafael Nadal'\n",
    "\n",
    "p1_final_rating = final_ratings[p1]\n",
    "p2_final_rating = final_ratings[p2]\n",
    "\n",
    "a = jnp.array([1, -1])\n",
    "\n",
    "# Comparing the two:\n",
    "print('Best of five: ', jnp.round(\n",
    "    calculate_win_prob_bo5(p1_final_rating, p2_final_rating, a, [1.], opt_params), 3))\n",
    "print('Best of three: ', jnp.round(\n",
    "    calculate_win_prob_bo5(p1_final_rating, p2_final_rating, a, [0.], opt_params), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(-0.62765106, dtype=float64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How well does this predict?\n",
    "win_probs = jnp.stack([x['prior_win_prob'] for x in history])\n",
    "jnp.mean(jnp.log(win_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(-0.62949445, dtype=float64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from jax_elo.utils.elo import optimise_static_k, compute_elo_ratings\n",
    "\n",
    "# What if we just fit basic Elo, ignoring slams?\n",
    "k, success = optimise_static_k(to_use['winner_name'], to_use['loser_name'])\n",
    "elo_pred = compute_elo_ratings(to_use['winner_name'], to_use['loser_name'], lambda _: k)\n",
    "elo_win_probs = [x['winner_prob'] for x in elo_pred]\n",
    "jnp.mean(jnp.log(jnp.array(elo_win_probs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as onp\n",
    "\n",
    "# So we're just a bit better, as you'd expect. What about at slams?\n",
    "result_df = to_use.copy()\n",
    "\n",
    "result_df['bo5_elo'] = onp.array(win_probs)\n",
    "result_df['elo'] = onp.array(elo_win_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df['is_bo5'] = is_bo5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So both predict better at slams, and the best of five version has a bigger edge there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_bo5\n",
       "False   -0.647\n",
       "True    -0.557\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.groupby('is_bo5').apply(lambda df: onp.mean(onp.log(df['elo']))).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_bo5\n",
       "False   -0.646\n",
       "True    -0.551\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.groupby('is_bo5').apply(lambda df: onp.mean(onp.log(df['bo5_elo']))).round(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
